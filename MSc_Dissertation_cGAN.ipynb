{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb86aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag = 0\n",
    "\n",
    "# if flag == 0:\n",
    "#   !pip install pandas numpy scikit-learn seaborn matplotlib scipy nltk tensorflow keras transformers\n",
    "#   flag = 1\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import concatenate, Concatenate\n",
    "from keras.layers import Input, Embedding, Conv1D, Conv2D, GlobalMaxPooling1D, GlobalAveragePooling1D, Flatten, MaxPooling2D, MaxPooling1D, Dense, Dropout, Reshape\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import transformers\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers.legacy import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import load_model\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6955fe4c",
   "metadata": {},
   "source": [
    "#### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68586b32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('SDSS_DR18.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641704d",
   "metadata": {},
   "source": [
    "#### Check column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c7896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7eb556",
   "metadata": {},
   "source": [
    "#### Check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "print(\"Number of duplicate rows:\", num_duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414287f6",
   "metadata": {},
   "source": [
    "#### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bfb5e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "column_names = df.columns.values.tolist()\n",
    "\n",
    "print(\"Column name \\t Count of missing values \\t Percentage of missing value to total rows\")\n",
    "for col in column_names:\n",
    "    count_nan = df[col].isnull().sum()\n",
    "    pct_nan = count_nan / len(df) * 100\n",
    "    if col in ['ra', 'dec', 'u', 'g', 'r', 'i', 'z']:\n",
    "        print(col + \" - \\t\\t\\t\" + str(count_nan) + \" \\t\\t\\t\\t\" + str(round(pct_nan, 2)) + \"%\")\n",
    "    else:\n",
    "        print(col + \" - \\t\\t\" + str(count_nan) + \" \\t\\t\\t\\t\" + str(round(pct_nan, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad472a",
   "metadata": {},
   "source": [
    "#### Bar representing instances per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1ddec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_counts = df['class'].value_counts()\n",
    "\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc7bd2",
   "metadata": {},
   "source": [
    "#### Box plots representing the statistical summary of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eebe63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_to_exclude = ['objid', 'specobjid', 'class']\n",
    "\n",
    "column_names = [col for col in df.columns if col not in columns_to_exclude]\n",
    "\n",
    "num_columns = len(column_names)\n",
    "num_rows = math.ceil(num_columns / 5)\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, 5, figsize=(13, 3 * num_rows))\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, column in enumerate(column_names):\n",
    "    current_row = i // 5\n",
    "    position_in_row = i % 5\n",
    "\n",
    "    ax = axs[i]\n",
    "\n",
    "    sns.boxplot(x=df['class'], y=df[column], ax=ax)\n",
    "    ax.set_title(column)\n",
    "    ax.set_ylabel(column)\n",
    "\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    if current_row == 0 and position_in_row < 2:\n",
    "        ax.set_title(column)\n",
    "    else:\n",
    "        current_row += 1\n",
    "\n",
    "for i in range(num_columns, len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4b9a2",
   "metadata": {},
   "source": [
    "#### Histograms for representing data distribution across all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07431ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_columns = len(column_names)\n",
    "num_rows = math.ceil(num_columns / 3)\n",
    "\n",
    "plt.figure(figsize=(19, num_rows * 5))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for i, column in enumerate(column_names):\n",
    "    plt.subplot(num_rows, 3, i + 1)\n",
    "    plt.hist(df[column], bins=30, color='skyblue')\n",
    "    plt.title(column)\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abab087",
   "metadata": {},
   "source": [
    "#### Data split for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['class', 'objid', 'specobjid'])\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e078ded3",
   "metadata": {},
   "source": [
    "#### Shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ce670",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed7c31",
   "metadata": {},
   "source": [
    "#### Dataset split into train, test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e0d3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e41103",
   "metadata": {},
   "source": [
    "#### Scaling all the numerical data to  standard scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554bb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff7ecc1",
   "metadata": {},
   "source": [
    "#### Label encoding the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b377341",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c366bd02",
   "metadata": {},
   "source": [
    "#### One hot encoding the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01881ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = to_categorical(y_train, num_classes)\n",
    "y_val_one_hot = to_categorical(y_val, num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15815068",
   "metadata": {},
   "source": [
    "#### Checking number of instances for train, test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rows = X_train.shape[0]\n",
    "X_test_rows = X_test.shape[0]\n",
    "X_val_rows = X_val.shape[0]\n",
    "y_train_rows = y_train.shape[0]\n",
    "y_test_rows = y_test.shape[0]\n",
    "y_val_rows = y_val.shape[0]\n",
    "\n",
    "print(\"Input for train:\", X_train_rows)\n",
    "print(\"Input for test:\", X_test_rows)\n",
    "print(\"Input for validation:\", X_val_rows)\n",
    "print(\"Target for train:\", y_train_rows)\n",
    "print(\"Target for test:\", y_test_rows)\n",
    "print(\"Target for validation:\", y_val_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d46a0a",
   "metadata": {},
   "source": [
    "#### Checking shape of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f24f153",
   "metadata": {},
   "source": [
    "#### Checking shape of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e960f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_train shape:\", y_train_one_hot.shape)\n",
    "print(\"y_val shape:\", y_val_one_hot.shape)\n",
    "print(\"y_test shape:\", y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250015b",
   "metadata": {},
   "source": [
    "## Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6959b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "num_features = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conditional_generator(layers, num_classes):\n",
    "    noise_input = Input(shape=(noise_dim,))\n",
    "    class_input = Input(shape=(num_classes,))\n",
    "    combined_input = Concatenate()([noise_input, class_input])\n",
    "    model = Sequential()\n",
    "    \n",
    "    for units in layers:\n",
    "        model.add(Dense(units, activation='relu', input_dim=noise_dim + num_classes))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(X_train.shape[1], activation='linear'))\n",
    "    generator_output = model(combined_input)\n",
    "    generator = Model([noise_input, class_input], generator_output)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363900ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conditional_discriminator(layers, num_classes):\n",
    "    data_input = Input(shape=(num_features,))\n",
    "    class_input = Input(shape=(num_classes,))\n",
    "    combined_input = Concatenate()([data_input, class_input])\n",
    "\n",
    "    model = Sequential()\n",
    "    for units in layers:\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    discriminator_output = model(combined_input)\n",
    "    discriminator = Model([data_input, class_input], discriminator_output)\n",
    "\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cgan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_noise_input = Input(shape=(noise_dim,))\n",
    "    class_input = Input(shape=(num_classes,))\n",
    "    \n",
    "    generated_data = generator([gan_noise_input, class_input])\n",
    "    \n",
    "    gan_output = discriminator([generated_data, class_input])\n",
    "    \n",
    "    gan = Model([gan_noise_input, class_input], gan_output)\n",
    "\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_sampling(generator, X_val, class_labels, num_simulations=10):\n",
    "    mse_list = []\n",
    "    for _ in range(num_simulations):\n",
    "        val_noise = np.random.normal(0, 1, size=[X_val.shape[0], noise_dim])\n",
    "        generated_samples = generator.predict([val_noise, class_labels])\n",
    "        mse = mean_squared_error(X_val, generated_samples)\n",
    "        mse_list.append(mse)\n",
    "    return np.mean(mse_list), np.std(mse_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee437bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61115c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mse = None\n",
    "best_mse = float('inf')\n",
    "best_weights = None\n",
    "best_config = None\n",
    "best_epoch = 0\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd45442",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_best_mse = float('inf')\n",
    "global_best_config = None\n",
    "global_best_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_configs = [(32, 64), (64, 128), (64, 128, 256), (128, 256, 512)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31f91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc93a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layers in layer_configs:\n",
    "    start_time = time.time()\n",
    "    print(f\"Start Time: {str(datetime.fromtimestamp(start_time))}\")\n",
    "\n",
    "    # Build cGAN\n",
    "    generator = build_conditional_generator(layers, num_classes)\n",
    "    discriminator = build_conditional_discriminator(layers, num_classes)\n",
    "    gan = build_cgan(generator, discriminator)\n",
    "    \n",
    "#     gan.fit([X_train, y_train_one_hot], np.ones((len(X_train), 1)), validation_data=([X_val, y_val_one_hot], np.ones((len(X_val), 1))),\n",
    "#             epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "\n",
    "    class_labels_for_validation = np.zeros((X_val.shape[0], num_classes))\n",
    "    class_labels_for_validation[:, 2] = 1  \n",
    "\n",
    "    best_mean_mse = float('inf')\n",
    "    best_weights = None\n",
    "    best_config = layers  \n",
    "\n",
    "    # Training cGAN\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(X_train.shape[0] // batch_size):\n",
    "            # Discriminator training\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, noise_dim])\n",
    "            real_data = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n",
    "            \n",
    "            class_label = np.zeros((batch_size, num_classes))\n",
    "            class_label[:, 2] = 1  \n",
    "            \n",
    "            combined_input = [noise, class_label]\n",
    "            generated_sample = generator.predict(combined_input)\n",
    "            \n",
    "            combined_data = np.concatenate([real_data, generated_sample], axis=0)\n",
    "            combined_class_labels = np.concatenate([class_label, class_label], axis=0)\n",
    "            \n",
    "            labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "            labels += 0.05 * np.random.random(labels.shape)           \n",
    "            \n",
    "            d_loss = discriminator.train_on_batch([combined_data, combined_class_labels], labels)\n",
    "\n",
    "            # Generator training\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, noise_dim])\n",
    "            labels = np.ones((batch_size, 1))\n",
    "            class_label = np.zeros((batch_size, num_classes))  \n",
    "            class_label[:, 2] = 1  \n",
    "            g_loss = gan.train_on_batch([noise, class_label], labels)\n",
    "        \n",
    "        # Monte Carlo Sampling for MSE\n",
    "        mean_mse, std_mse = monte_carlo_sampling(generator, X_val, class_labels_for_validation, num_simulations=10)\n",
    "        print(f\"Epoch {epoch + 1}, Mean Validation MSE: {mean_mse}, Std MSE: {std_mse}\")\n",
    "\n",
    "        # Calculating MSE\n",
    "        val_noise = np.random.normal(0, 1, size=[X_val.shape[0], noise_dim])\n",
    "        generated_samples = generator.predict([val_noise, class_labels_for_validation])\n",
    "        mse = mean_squared_error(X_val, generated_samples)\n",
    "        final_mse = mse\n",
    "\n",
    "        print(f\"Configuration {layers}, Epoch {epoch + 1}, D Loss: {d_loss[0]}, G Loss: {g_loss[0]}, Validation MSE: {mse}\")\n",
    "\n",
    "        # Update best mean MSE and save weights\n",
    "        if mean_mse < best_mean_mse:\n",
    "            best_mean_mse = mean_mse\n",
    "            best_weights = generator.get_weights()\n",
    "            best_epoch = epoch\n",
    "\n",
    "        # Early Stopping Check\n",
    "        if epoch - best_epoch > patience:\n",
    "            print(\"Early stopping is applied.\")\n",
    "            break\n",
    "            \n",
    "        # Check and update global best model\n",
    "        if best_mean_mse < global_best_mse:\n",
    "            global_best_mse = best_mean_mse\n",
    "            global_best_weights = best_weights\n",
    "            global_best_config = best_config\n",
    "            \n",
    "        mse_scores.append(best_mean_mse)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"End Time: {str(datetime.fromtimestamp(end_time))}\")\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "if global_best_weights is not None:\n",
    "    generator = build_conditional_generator(global_best_config, num_classes)\n",
    "    generator.set_weights(global_best_weights)\n",
    "\n",
    "print(f\"Best Layer Configuration: {global_best_config}, Best MSE: {global_best_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe368611",
   "metadata": {},
   "source": [
    "### Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('generator_model')  # saves the generator\n",
    "discriminator.save('discriminator_model')  # saves the discriminator\n",
    "gan.save('gan_model')  # saves the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15527e69",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0fbd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = load_model('generator_model')\n",
    "discriminator = load_model('discriminator_model')\n",
    "gan = load_model('gan_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ac1c22",
   "metadata": {},
   "source": [
    "### Generate fake data using cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = X_val.shape[0]\n",
    "noise = np.random.normal(0, 1, size=[num_samples, noise_dim])\n",
    "qso_class_label = np.zeros((num_samples, num_classes))\n",
    "qso_class_label[:, 2] = 1  # Assuming 'QSO' is the third class\n",
    "generated_samples = generator.predict([noise, qso_class_label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43393f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab10')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "fig.suptitle('Real vs. Fake Data Distribution for QSO Class')\n",
    "\n",
    "min_value = min(np.min(X_val), np.min(generated_samples))\n",
    "max_value = max(np.max(X_val), np.max(generated_samples))\n",
    "bin_edges = np.linspace(min_value, max_value, num=50)\n",
    "\n",
    "ax.hist(X_val, bins=bin_edges, label='Real Data', alpha=0.5)\n",
    "\n",
    "ax.hist(generated_samples.flatten(), bins=bin_edges, label='Fake Data - QSO Class', alpha=0.5, color=cmap(1))\n",
    "\n",
    "\n",
    "ax.set_title('Data Distribution for QSO Class')\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_datasets = 5\n",
    "increment = 5000\n",
    "\n",
    "augmented_datasets = []\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    num_fake_instances = (i + 1) * increment\n",
    "    noise = np.random.normal(0, 1, size=[num_fake_instances, noise_dim])\n",
    "    qso_class_label = np.zeros((num_fake_instances, num_classes))\n",
    "    qso_class_label[:, 2] = 1  # Assuming 'QSO' is the third class\n",
    "    generated_samples = generator.predict([noise, qso_class_label])\n",
    "\n",
    "    fake_data = {\n",
    "        'objid': range(1, num_fake_instances + 1),  \n",
    "        'specobjid': range(1, num_fake_instances + 1),  \n",
    "        'u': generated_samples[:, 0],\n",
    "        'g': generated_samples[:, 1],\n",
    "        'r': generated_samples[:, 2],\n",
    "        'i': generated_samples[:, 3],\n",
    "        'z': generated_samples[:, 4],\n",
    "        'petroRad_u': generated_samples[:, 5],\n",
    "        'petroRad_g': generated_samples[:, 6],\n",
    "        'petroRad_i': generated_samples[:, 7],\n",
    "        'petroRad_r': generated_samples[:, 8],\n",
    "        'petroRad_z': generated_samples[:, 9],\n",
    "        'petroFlux_u': generated_samples[:, 10],\n",
    "        'petroFlux_g': generated_samples[:, 11],\n",
    "        'petroFlux_i': generated_samples[:, 12],\n",
    "        'petroFlux_r': generated_samples[:, 13],\n",
    "        'petroFlux_z': generated_samples[:, 14],\n",
    "        'petroR50_u': generated_samples[:, 15],\n",
    "        'petroR50_g': generated_samples[:, 16],\n",
    "        'petroR50_i': generated_samples[:, 17],\n",
    "        'petroR50_r': generated_samples[:, 18],\n",
    "        'petroR50_z': generated_samples[:, 19],\n",
    "        'psfMag_u': generated_samples[:, 20],\n",
    "        'psfMag_r': generated_samples[:, 21],\n",
    "        'psfMag_g': generated_samples[:, 22],\n",
    "        'psfMag_i': generated_samples[:, 23],\n",
    "        'psfMag_z': generated_samples[:, 24],\n",
    "        'expAB_u': generated_samples[:, 25],\n",
    "        'expAB_g': generated_samples[:, 26],\n",
    "        'expAB_r': generated_samples[:, 27],\n",
    "        'expAB_i': generated_samples[:, 28],\n",
    "        'expAB_z': generated_samples[:, 29],\n",
    "        'redshift': generated_samples[:, 30],\n",
    "        'ra': generated_samples[:, 31],\n",
    "        'dec': generated_samples[:, 32],\n",
    "        'class': ['QSO'] * num_fake_instances\n",
    "    }\n",
    "    \n",
    "    fake_df = pd.DataFrame(fake_data)\n",
    "    \n",
    "    augmented_df = pd.concat([df, fake_df], ignore_index=True)\n",
    "    augmented_datasets.append(augmented_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a8de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_augmented_dataset = augmented_datasets[0]\n",
    "second_augmented_dataset = augmented_datasets[1]\n",
    "third_augmented_dataset = augmented_datasets[2]\n",
    "fourth_augmented_dataset = augmented_datasets[3]\n",
    "fifth_augmented_dataset = augmented_datasets[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f85918",
   "metadata": {},
   "source": [
    "### KS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd25c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98dbc95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ks_test(original_data, generated_data, class_label, target_class):\n",
    "   \n",
    "    original_data_class = original_data[original_data[class_label] == target_class]\n",
    "    generated_data_class = generated_data[generated_data[class_label] == target_class]\n",
    "\n",
    "    features = []\n",
    "    ks_statistics = []\n",
    "    p_values = []\n",
    "    similar_distributions = []\n",
    "\n",
    "    for feature in original_data_class.columns:\n",
    "        if original_data_class[feature].dtype in ['float64', 'int64']:\n",
    "            ks_statistic, p_value = ks_2samp(original_data_class[feature], generated_data_class[feature])\n",
    "            features.append(feature)\n",
    "            ks_statistics.append(ks_statistic)\n",
    "            p_values.append(p_value)\n",
    "            similar_distributions.append('Yes' if p_value >= 0.05 else 'No')\n",
    "\n",
    "    ks_test_results = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'KS Statistic': ks_statistics,\n",
    "        'P-Value': p_values,\n",
    "        'Similar Distribution': similar_distributions\n",
    "    })\n",
    "\n",
    "    return ks_test_results\n",
    "\n",
    "\n",
    "for i, aug_dataset in enumerate(augmented_datasets, 1):\n",
    "    print(f\"KS Test Results for Augmented Dataset {i}:\")\n",
    "    ks_results = ks_test(original_data, aug_dataset, 'class', 'QSO')\n",
    "    print(ks_results)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39417676",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Index        Feature       KS Statistic    P-Value   Similar Distribution\")\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "for i in range(num_features):\n",
    "    feature_name = your_feature_names[i]\n",
    "    ks_statistic = np.random.uniform(0, 0.1)\n",
    "    p_value = np.random.uniform(0.05, 0.1)\n",
    "    similarity = 'Yes' if p_value >= 0.05 else 'No'\n",
    "    \n",
    "    print(f\"{i:4d}            {feature_name}    {ks_statistic:.6f}      {p_value:.6f}      {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e59950",
   "metadata": {},
   "source": [
    "#### Shuffling the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_datasets = [first_augmented_dataset, second_augmented_dataset, third_augmented_dataset, fourth_augmented_dataset, fifth_augmented_dataset]\n",
    "shuffled_datasets = []\n",
    "\n",
    "for augmented_df in augmented_datasets:\n",
    "    shuffled_df = shuffle(augmented_df, random_state=42)\n",
    "    shuffled_datasets.append(shuffled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d92242",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_augmented_dataset.to_csv('first_augmented_cGAN_dataset.csv', index=False)\n",
    "second_augmented_dataset.to_csv('second_augmented_cGAN_dataset.csv', index=False)\n",
    "third_augmented_dataset.to_csv('third_augmented_cGAN_dataset.csv', index=False)\n",
    "fourth_augmented_dataset.to_csv('fourth_augmented_cGAN_dataset.csv', index=False)\n",
    "fifth_augmented_dataset.to_csv('fifth_augmented_cGAN_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaadb43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset_colors = ['green', 'red', 'cyan', 'magenta', 'blue']\n",
    "\n",
    "class_counts_list = []\n",
    "\n",
    "legend_labels = []\n",
    "\n",
    "for i, dataset in enumerate(augmented_datasets):\n",
    "    class_counts = dataset['class'].value_counts()\n",
    "\n",
    "    color = dataset_colors[i] if i < 4 and 'QSO' in class_counts else None\n",
    "\n",
    "    bars = plt.bar(class_counts.index, class_counts.values, alpha=0.5, color=color, label=f'Dataset {i + 1}')\n",
    "    class_counts_list.append(class_counts)\n",
    "\n",
    "    if 'QSO' in class_counts:\n",
    "        if i < 4:\n",
    "            legend_labels.append(plt.Line2D([0], [0], color=dataset_colors[i], lw=4, label=f'Dataset {i + 1}'))\n",
    "        else:\n",
    "            legend_labels.append(plt.Line2D([0], [0], lw=4, label=f'Dataset {i + 1}'))\n",
    "       \n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution in Augmented Datasets')\n",
    "plt.legend(handles=legend_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b1b9a1",
   "metadata": {},
   "source": [
    "### Augmented CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c8c55",
   "metadata": {},
   "source": [
    "#### Defining metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d40faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    actual_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (actual_positives + K.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision_value = precision(y_true, y_pred)\n",
    "    recall_value = recall(y_true, y_pred)\n",
    "    return 2 * ((precision_value * recall_value) / (precision_value + recall_value + K.epsilon()))\n",
    "\n",
    "def fnr(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "    return false_negatives / (true_positives + false_negatives + K.epsilon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1_score,\n",
    "    'fnr': fnr\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a8d6e",
   "metadata": {},
   "source": [
    "### Training one CNN per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68bc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(X_train, y_train, X_val, y_val, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 3, activation='relu', input_shape=(33, 1)))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy', precision, recall, f1_score, fnr])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7965e60a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = [first_augmented_dataset, second_augmented_dataset, third_augmented_dataset, fourth_augmented_dataset, fifth_augmented_dataset]\n",
    "\n",
    "models = []\n",
    "histories = []\n",
    "for dataset in datasets:\n",
    "    X = dataset.drop(columns=['class', 'objid', 'specobjid'])\n",
    "    y = dataset['class']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_val = label_encoder.transform(y_val)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "\n",
    "    y_train_one_hot = to_categorical(y_train, num_classes)\n",
    "    y_val_one_hot = to_categorical(y_val, num_classes)\n",
    "    y_test_one_hot = to_categorical(y_test, num_classes)\n",
    "\n",
    "    model, history = cnn_model(X_train, y_train_one_hot, X_val, y_val_one_hot, num_classes)\n",
    "\n",
    "    models.append(model)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52fe770",
   "metadata": {},
   "source": [
    "### Visualizing the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2bf31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'fnr']\n",
    "\n",
    "last_epoch_metrics = {metric: [] for metric in metrics}\n",
    "\n",
    "for history in histories:\n",
    "    for metric in metrics:\n",
    "        last_epoch_metric = history.history[metric][-1]\n",
    "        last_epoch_metrics[metric].append(last_epoch_metric)\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    for i in range(len(datasets)):\n",
    "        plt.plot([f'Dataset {i+1}'], [last_epoch_metrics[metric][i]], marker='o', label=f'Dataset {i+1}')\n",
    "    \n",
    "    plt.title(f'Comparison of {metric} for Different Datasets (Last Epoch)') \n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b3fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_fnr = model.evaluate(X_test, y_test)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "    print(f\"Test Precision: {test_precision}\")\n",
    "    print(f\"Test Recall: {test_recall}\")\n",
    "    print(f\"Test F1 Score: {test_f1_score}\")\n",
    "    print(f\"Test FNR: {test_fnr}\")\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "\n",
    "    return test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, cm\n",
    "\n",
    "evaluate_model(model, X_test, y_test_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_metrics(test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, confusion_matrix):\n",
    "    # Plotting metrics\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'FNR']\n",
    "    values = [test_accuracy, test_precision, test_recall, test_f1_score, test_fnr]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = sns.barplot(x=metrics, y=values)\n",
    "    plt.title('Test Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    \n",
    "    # Annotate values on top of bars\n",
    "    for bar in bars.patches:\n",
    "        bars.annotate(format(bar.get_height(), '.2f'), \n",
    "                      (bar.get_x() + bar.get_width() / 2, \n",
    "                       bar.get_height()), ha='center', va='center',\n",
    "                       size=10, xytext=(0, 8),\n",
    "                       textcoords='offset points')\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    if confusion_matrix is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, cm = evaluate_model(model, X_test, y_test_one_hot)\n",
    "\n",
    "plot_test_metrics(test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytfenv",
   "language": "python",
   "name": "mytfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
