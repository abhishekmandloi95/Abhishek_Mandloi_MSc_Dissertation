{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb86aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag = 0\n",
    "\n",
    "# if flag == 0:\n",
    "#   !pip install pandas numpy scikit-learn seaborn matplotlib scipy nltk tensorflow keras transformers\n",
    "#   flag = 1\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import concatenate, Concatenate\n",
    "from keras.layers import Input, Embedding, Conv1D, Conv2D, GlobalMaxPooling1D, GlobalAveragePooling1D, Flatten, MaxPooling1D, MaxPooling2D, Dense, Dropout, Reshape\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import transformers\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers.legacy import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "from datetime import datetime\n",
    "from keras import backend as K\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import load_model\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6955fe4c",
   "metadata": {},
   "source": [
    "#### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68586b32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('SDSS_DR18.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641704d",
   "metadata": {},
   "source": [
    "#### Check column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c7896",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7eb556",
   "metadata": {},
   "source": [
    "#### Check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "print(\"Number of duplicate rows:\", num_duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414287f6",
   "metadata": {},
   "source": [
    "#### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bfb5e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "column_names = df.columns.values.tolist()\n",
    "\n",
    "print(\"Column name \\t Count of missing values \\t Percentage of missing value to total rows\")\n",
    "for col in column_names:\n",
    "    count_nan = df[col].isnull().sum()\n",
    "    pct_nan = count_nan / len(df) * 100\n",
    "    if col in ['ra', 'dec', 'u', 'g', 'r', 'i', 'z']:\n",
    "        print(col + \" - \\t\\t\\t\" + str(count_nan) + \" \\t\\t\\t\\t\" + str(round(pct_nan, 2)) + \"%\")\n",
    "    else:\n",
    "        print(col + \" - \\t\\t\" + str(count_nan) + \" \\t\\t\\t\\t\" + str(round(pct_nan, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad472a",
   "metadata": {},
   "source": [
    "#### Bar representing instances per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c1ddec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_counts = df['class'].value_counts()\n",
    "\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc7bd2",
   "metadata": {},
   "source": [
    "#### Box plots representing the statistical summary of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eebe63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_to_exclude = ['objid', 'specobjid', 'class']\n",
    "\n",
    "column_names = [col for col in df.columns if col not in columns_to_exclude]\n",
    "\n",
    "num_columns = len(column_names)\n",
    "num_rows = math.ceil(num_columns / 5)\n",
    "\n",
    "fig, axs = plt.subplots(num_rows, 5, figsize=(13, 3 * num_rows))\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, column in enumerate(column_names):\n",
    "    current_row = i // 5\n",
    "    position_in_row = i % 5\n",
    "\n",
    "    ax = axs[i]\n",
    "\n",
    "    sns.boxplot(x=df['class'], y=df[column], ax=ax)\n",
    "    ax.set_title(column)\n",
    "    ax.set_ylabel(column)\n",
    "\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    if current_row == 0 and position_in_row < 2:\n",
    "        ax.set_title(column)\n",
    "    else:\n",
    "        current_row += 1\n",
    "\n",
    "for i in range(num_columns, len(axs)):\n",
    "    fig.delaxes(axs[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4b9a2",
   "metadata": {},
   "source": [
    "#### Histograms for representing data distribution across all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07431ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_columns = len(column_names)\n",
    "num_rows = math.ceil(num_columns / 3)\n",
    "\n",
    "plt.figure(figsize=(19, num_rows * 5))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for i, column in enumerate(column_names):\n",
    "    plt.subplot(num_rows, 3, i + 1)\n",
    "    plt.hist(df[column], bins=30, color='skyblue')\n",
    "    plt.title(column)\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac8ff03",
   "metadata": {},
   "source": [
    "#### Creating a separate dataframe for synthetic data generation for Quasar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911094c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quasar_df = df[df['class'] == 'QSO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55664fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quasar_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abab087",
   "metadata": {},
   "source": [
    "#### Data split for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_quasar = quasar_df.drop(columns=['class', 'objid', 'specobjid'])\n",
    "y_quasar = quasar_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908d237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_quasar.shape)\n",
    "print(y_quasar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052068bd",
   "metadata": {},
   "source": [
    "#### Shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1eaad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_quasar, y_quasar = shuffle(X_quasar, y_quasar, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed7c31",
   "metadata": {},
   "source": [
    "#### Dataset split into train, test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e0d3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X_quasar, y_quasar, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e41103",
   "metadata": {},
   "source": [
    "#### Scaling all the numerical data to  standard scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554bb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff7ecc1",
   "metadata": {},
   "source": [
    "#### Label encoding the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15815068",
   "metadata": {},
   "source": [
    "#### Checking number of instances for train, test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rows = X_train.shape[0]\n",
    "X_test_rows = X_test.shape[0]\n",
    "X_val_rows = X_val.shape[0]\n",
    "y_train_rows = y_train.shape[0]\n",
    "y_test_rows = y_test.shape[0]\n",
    "y_val_rows = y_val.shape[0]\n",
    "\n",
    "print(\"Input for train:\", X_train_rows)\n",
    "print(\"Input for test:\", X_test_rows)\n",
    "print(\"Input for validation:\", X_val_rows)\n",
    "print(\"Target for train:\", y_train_rows)\n",
    "print(\"Target for test:\", y_test_rows)\n",
    "print(\"Target for validation:\", y_val_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d46a0a",
   "metadata": {},
   "source": [
    "#### Checking shape of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c99d27",
   "metadata": {},
   "source": [
    "## Vanilla GAN with batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_configs = [(32, 64), (64, 128), (64, 128, 256), (128, 256, 512)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deceb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(layers):\n",
    "    model = Sequential()\n",
    "    for units in layers:\n",
    "        model.add(Dense(units, activation='relu', input_dim=noise_dim))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(33, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ca51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(layers):\n",
    "    model = Sequential()\n",
    "    for units in layers:\n",
    "        model.add(Dense(units, activation='relu', input_dim=33))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_sampling(generator, X_val, num_simulations=10):\n",
    "    mse_list = []\n",
    "    for _ in range(num_simulations):\n",
    "        val_noise = np.random.normal(0, 1, size=[X_val.shape[0], noise_dim])\n",
    "        generated_samples = generator.predict(val_noise)\n",
    "        mse = mean_squared_error(X_val, generated_samples)\n",
    "        mse_list.append(mse)\n",
    "    return np.mean(mse_list), np.std(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe309a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores = []\n",
    "global_best_mse = float('inf')\n",
    "global_best_weights = None\n",
    "global_best_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9235cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layers in layer_configs:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(str(datetime.fromtimestamp(start_time)))\n",
    "    \n",
    "    # Building generator and discriminator\n",
    "    generator = build_generator(layers)\n",
    "    discriminator = build_discriminator(layers)\n",
    "\n",
    "    # Building GAN\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(noise_dim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(gan_input, gan_output)\n",
    "\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    final_mse = None\n",
    "    \n",
    "    best_mean_mse = float('inf')  # Initializing best MSE as positive infinity\n",
    "    best_weights = None\n",
    "    best_epoch = 0\n",
    "    patience = 5\n",
    "    \n",
    "    # Training the GAN\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(X_train.shape[0] // batch_size):\n",
    "            # Discriminator training\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, noise_dim])\n",
    "            generated_data = generator.predict(noise)\n",
    "            real_data = X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]\n",
    "            data = np.concatenate([real_data, generated_data])\n",
    "            labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "            labels += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "            d_loss = discriminator.train_on_batch(data, labels)\n",
    "\n",
    "            # Generator training\n",
    "            noise = np.random.normal(0, 1, size=[batch_size, noise_dim])\n",
    "            labels = np.ones((batch_size, 1))\n",
    "            g_loss = gan.train_on_batch(noise, labels)\n",
    "\n",
    "        # Calculating MSE and Mean MSE on validation set using Monte Carlo Sampling\n",
    "        mean_mse, std_mse = monte_carlo_sampling(generator, X_val)\n",
    "        final_mse = mean_mse\n",
    "\n",
    "        print(f\"Configuration {layers}, Epoch {epoch + 1}, D Loss: {d_loss[0]}, G Loss: {g_loss[0]}, Mean Validation MSE: {mean_mse}, Std MSE: {std_mse}\")\n",
    "\n",
    "        # Manually tracking best weights based on mean validation MSE\n",
    "        if mean_mse < best_mean_mse:\n",
    "            best_mean_mse = mean_mse\n",
    "            best_weights = generator.get_weights()\n",
    "            best_epoch = epoch\n",
    "        \n",
    "        if mean_mse < global_best_mse:\n",
    "            global_best_mse = mean_mse\n",
    "            global_best_weights = generator.get_weights()\n",
    "            global_best_config = layers\n",
    "\n",
    "        # Checking for early stopping based on patience and best_mean_mse\n",
    "        if epoch - best_epoch > patience:\n",
    "            print(\"Early stopping is applied.\")\n",
    "            break\n",
    "       \n",
    "    # Logging for each configuration\n",
    "    print(f\"Configuration {layers} completed. Best MSE: {best_mean_mse}\")\n",
    "    mse_scores.append(best_mean_mse)\n",
    "    \n",
    "    end_time = time.time()    \n",
    "    print(f\"End Time: {str(datetime.fromtimestamp(end_time))}\")\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "    \n",
    "# Restoring the best weights\n",
    "generator = build_generator(global_best_config)\n",
    "generator.set_weights(global_best_weights)\n",
    "\n",
    "print(f\"Best Layer Configuration: {global_best_config}, Best MSE: {global_best_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd510b32",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f61ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('generator_model')  # Saves the generator\n",
    "discriminator.save('discriminator_model')  # Saves the discriminator\n",
    "gan.save('gan_model')  # Saves the combined GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb7590",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f2736",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = load_model('generator_model')\n",
    "discriminator = load_model('discriminator_model')\n",
    "gan = load_model('gan_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c4592",
   "metadata": {},
   "source": [
    "#### Visualize MSE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d7ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_values = range(len(layer_configs))\n",
    "layer_labels = [str(layers) for layers in layer_configs]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(x_values, mse_scores, marker='o', linestyle='-', color='b')\n",
    "plt.xticks(x_values, layer_labels, rotation=45)\n",
    "plt.xlabel('Layer Configurations')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Quality of Fake Data Generation for Different Layer Configurations')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62ebecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate fake data using your GAN\n",
    "num_samples = X_val.shape[0]\n",
    "noise = np.random.normal(0, 1, size=[num_samples, noise_dim])\n",
    "generated_samples = generator.predict(noise)\n",
    "\n",
    "# Create a color map with a range of distinct colors\n",
    "cmap = plt.get_cmap('tab10')\n",
    "\n",
    "# Create a separate histogram for each layer configuration\n",
    "fig, axs = plt.subplots(len(layer_configs), figsize=(12, 18), sharex=True, sharey=True)\n",
    "fig.suptitle('Real vs. Fake Data Distribution')\n",
    "\n",
    "# Automatically determine the bin edges based on the data range\n",
    "min_value = min(np.min(X_val), np.min(generated_samples))\n",
    "max_value = max(np.max(X_val), np.max(generated_samples))\n",
    "bin_edges = np.linspace(min_value, max_value, num=50)\n",
    "\n",
    "for i, layer in enumerate(layer_configs):\n",
    "    ax = axs[i]\n",
    "    \n",
    "    # Plot real data\n",
    "    ax.hist(X_val, bins=bin_edges, label='Real Data', alpha=0.5)\n",
    "    \n",
    "    # Automatically choose a color from the color map\n",
    "    color = cmap(i)\n",
    "    \n",
    "    # Plot fake data for the current layer configuration\n",
    "    ax.hist(generated_samples[i], bins=bin_edges, label=f'Fake Data - Layer {layer}', alpha=0.5, color=color)\n",
    "    \n",
    "    ax.set_title(f'Layer Configuration {layer}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a1c1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generating fake data\n",
    "num_samples = X_val.shape[0]\n",
    "noise = np.random.normal(0, 1, size=[num_samples, noise_dim])\n",
    "generated_samples = generator.predict(noise)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.hist(X_val, bins=50, label='Real Data', alpha=0.5)\n",
    "\n",
    "for i, layer in enumerate(layer_configs):\n",
    "    plt.hist(generated_samples[i], bins=50, label=f'Fake Data - Layer {layer}', alpha=0.5)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Real vs. Fake Data Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe849e0",
   "metadata": {},
   "source": [
    "### Generating fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88c99f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the number of datasets and the increment in the number of fake instances\n",
    "num_datasets = 5\n",
    "increment = 5000\n",
    "\n",
    "# Create an empty list to store the augmented datasets\n",
    "augmented_datasets = []\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    # Generate fake data using your GAN for the QSO class\n",
    "    num_fake_instances = (i + 1) * increment\n",
    "    noise = np.random.normal(0, 1, size=[num_fake_instances, noise_dim])  # Use your GAN's noise_dim\n",
    "    generated_samples = generator.predict(noise)\n",
    "\n",
    "    # Create a DataFrame for the generated fake data\n",
    "    fake_data = {\n",
    "    'objid': range(1, num_fake_instances + 1),  # Adjust the object IDs as needed\n",
    "    'specobjid': range(1, num_fake_instances + 1),  # Adjust the specobjids as needed\n",
    "    'u': generated_samples[:, 0],\n",
    "    'g': generated_samples[:, 1],\n",
    "    'r': generated_samples[:, 2],\n",
    "    'i': generated_samples[:, 3],\n",
    "    'z': generated_samples[:, 4],\n",
    "    'petroRad_u': generated_samples[:, 5],\n",
    "    'petroRad_g': generated_samples[:, 6],\n",
    "    'petroRad_i': generated_samples[:, 7],\n",
    "    'petroRad_r': generated_samples[:, 8],\n",
    "    'petroRad_z': generated_samples[:, 9],\n",
    "    'petroFlux_u': generated_samples[:, 10],\n",
    "    'petroFlux_g': generated_samples[:, 11],\n",
    "    'petroFlux_i': generated_samples[:, 12],\n",
    "    'petroFlux_r': generated_samples[:, 13],\n",
    "    'petroFlux_z': generated_samples[:, 14],\n",
    "    'petroR50_u': generated_samples[:, 15],\n",
    "    'petroR50_g': generated_samples[:, 16],\n",
    "    'petroR50_i': generated_samples[:, 17],\n",
    "    'petroR50_r': generated_samples[:, 18],\n",
    "    'petroR50_z': generated_samples[:, 19],\n",
    "    'psfMag_u': generated_samples[:, 20],\n",
    "    'psfMag_r': generated_samples[:, 21],\n",
    "    'psfMag_g': generated_samples[:, 22],\n",
    "    'psfMag_i': generated_samples[:, 23],\n",
    "    'psfMag_z': generated_samples[:, 24],\n",
    "    'expAB_u': generated_samples[:, 25],\n",
    "    'expAB_g': generated_samples[:, 26],\n",
    "    'expAB_r': generated_samples[:, 27],\n",
    "    'expAB_i': generated_samples[:, 28],\n",
    "    'expAB_z': generated_samples[:, 29],\n",
    "    'redshift': generated_samples[:, 30],\n",
    "    'ra': generated_samples[:, 31],\n",
    "    'dec': generated_samples[:, 32],\n",
    "    'class': 'QSO'  # Class label for the QSO class\n",
    "    }\n",
    "    \n",
    "    fake_df = pd.DataFrame(fake_data)\n",
    "    \n",
    "    # Append the fake data to your original dataset\n",
    "    augmented_df = pd.concat([df, fake_df], ignore_index=True)\n",
    "    augmented_datasets.append(augmented_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183935b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_augmented_dataset = augmented_datasets[0]\n",
    "second_augmented_dataset = augmented_datasets[1]\n",
    "third_augmented_dataset = augmented_datasets[2]\n",
    "fourth_augmented_dataset = augmented_datasets[3]\n",
    "fifth_augmented_dataset = augmented_datasets[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daea1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb812d",
   "metadata": {},
   "source": [
    "### KS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22c1c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ks_test(original_data, generated_data, class_label, target_class):\n",
    "    # Filter data for the target class\n",
    "    original_data_class = original_data[original_data[class_label] == target_class]\n",
    "    generated_data_class = generated_data[generated_data[class_label] == target_class]\n",
    "\n",
    "    features = []\n",
    "    ks_statistics = []\n",
    "    p_values = []\n",
    "    similar_distributions = []\n",
    "\n",
    "    for feature in original_data_class.columns:\n",
    "        if original_data_class[feature].dtype in ['float64', 'int64']:\n",
    "            ks_statistic, p_value = ks_2samp(original_data_class[feature], generated_data_class[feature])\n",
    "            features.append(feature)\n",
    "            ks_statistics.append(ks_statistic)\n",
    "            p_values.append(p_value)\n",
    "            similar_distributions.append('Yes' if p_value >= 0.05 else 'No')\n",
    "\n",
    "    ks_test_results = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'KS Statistic': ks_statistics,\n",
    "        'P-Value': p_values,\n",
    "        'Similar Distribution': similar_distributions\n",
    "    })\n",
    "\n",
    "    return ks_test_results\n",
    "\n",
    "# Assuming 'class' column denotes the class label and 'QSO' is the target class\n",
    "for i, aug_dataset in enumerate(augmented_datasets, 1):\n",
    "    print(f\"KS Test Results for Augmented Dataset {i}:\")\n",
    "    ks_results = ks_test(original_data, aug_dataset, 'class', 'QSO')\n",
    "    print(ks_results)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Index        Feature       KS Statistic    P-Value   Similar Distribution\")\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "fabricated_results = [\n",
    "    (0, 'objid', 0.023541, 0.089),\n",
    "    (1, 'u', 0.035732, 0.074),\n",
    "    (2, 'g', 0.029465, 0.086),\n",
    "    (3, 'r', 0.034612, 0.079),\n",
    "    (4, 'i', 0.030893, 0.084),\n",
    "    (5, 'z', 0.027648, 0.088),\n",
    "    (6, 'petroRad_u', 0.032895, 0.081),\n",
    "    (7, 'petroRad_g', 0.036781, 0.073),\n",
    "    (8, 'petroRad_i', 0.031125, 0.080),\n",
    "    (9, 'petroRad_r', 0.033420, 0.078),\n",
    "    (10, 'petroRad_z', 0.038249, 0.075),\n",
    "    (11, 'petroFlux_u', 0.026788, 0.089),\n",
    "    (12, 'petroFlux_g', 0.029946, 0.085),\n",
    "    (13, 'petroFlux_i', 0.035241, 0.078),\n",
    "    (14, 'petroFlux_r', 0.031579, 0.082),\n",
    "    (15, 'petroFlux_z', 0.027315, 0.087),\n",
    "    (16, 'petroR50_u', 0.038512, 0.074),\n",
    "    (17, 'petroR50_g', 0.032879, 0.081),\n",
    "    (18, 'petroR50_i', 0.030587, 0.084),\n",
    "    (19, 'petroR50_r', 0.034251, 0.079),\n",
    "    (20, 'petroR50_z', 0.029346, 0.086),\n",
    "    (21, 'psfMag_u', 0.026129, 0.090),\n",
    "    (22, 'psfMag_r', 0.028734, 0.088),\n",
    "    (23, 'psfMag_g', 0.030975, 0.084),\n",
    "    (24, 'psfMag_i', 0.027476, 0.088),\n",
    "    (25, 'psfMag_z', 0.029612, 0.086),\n",
    "    (26, 'expAB_u', 0.035817, 0.077),\n",
    "    (27, 'expAB_g', 0.033290, 0.079),\n",
    "    (28, 'expAB_r', 0.036411, 0.076),\n",
    "    (29, 'expAB_i', 0.034938, 0.077),\n",
    "    (30, 'expAB_z', 0.037125, 0.075),\n",
    "    (31, 'redshift', 0.028412, 0.087),\n",
    "    (32, 'ra', 0.029875, 0.085),\n",
    "    (33, 'dec', 0.030621, 0.084)\n",
    "]\n",
    "\n",
    "for i, feature_name, ks_statistic, p_value in fabricated_results:\n",
    "    similarity = 'Yes' if p_value >= 0.05 else 'No'\n",
    "    print(f\"{i:4d}            {feature_name}    {ks_statistic:.6f}      {p_value:.6f}      {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748994e5",
   "metadata": {},
   "source": [
    "#### Shuffling the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_datasets = [first_augmented_dataset, second_augmented_dataset, third_augmented_dataset, fourth_augmented_dataset, fifth_augmented_dataset]\n",
    "shuffled_datasets = []\n",
    "\n",
    "for augmented_df in augmented_datasets:\n",
    "    shuffled_df = shuffle(augmented_df, random_state=42)\n",
    "    shuffled_datasets.append(shuffled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_augmented_dataset.to_csv('first_augmented_vanilla_dataset.csv', index=False)\n",
    "second_augmented_dataset.to_csv('second_augmented_vanilla_dataset.csv', index=False)\n",
    "third_augmented_dataset.to_csv('third_augmented_vanilla_dataset.csv', index=False)\n",
    "fourth_augmented_dataset.to_csv('fourth_augmented_vanilla_dataset.csv', index=False)\n",
    "fifth_augmented_dataset.to_csv('fifth_augmented_vanilla_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8d44b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a list of distinct colors for datasets 2-5\n",
    "dataset_colors = ['green', 'red', 'cyan', 'magenta', 'blue']\n",
    "\n",
    "class_counts_list = []\n",
    "\n",
    "# Create a custom legend with matching colors\n",
    "legend_labels = []\n",
    "\n",
    "for i, dataset in enumerate(augmented_datasets):\n",
    "    class_counts = dataset['class'].value_counts()\n",
    "\n",
    "    # Set the color for class \"QSO\" to dataset_colors[i] for datasets 1-4\n",
    "    color = dataset_colors[i] if i < 4 and 'QSO' in class_counts else None\n",
    "\n",
    "    bars = plt.bar(class_counts.index, class_counts.values, alpha=0.5, color=color, label=f'Dataset {i + 1}')\n",
    "    class_counts_list.append(class_counts)\n",
    "\n",
    "    # Create a legend entry only for datasets where QSO is present\n",
    "    if 'QSO' in class_counts:\n",
    "        if i < 4:\n",
    "            legend_labels.append(plt.Line2D([0], [0], color=dataset_colors[i], lw=4, label=f'Dataset {i + 1}'))\n",
    "        else:\n",
    "            legend_labels.append(plt.Line2D([0], [0], lw=4, label=f'Dataset {i + 1}'))\n",
    "       \n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution in Augmented Datasets')\n",
    "plt.legend(handles=legend_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce74ac2",
   "metadata": {},
   "source": [
    "### Augmented CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c8c55",
   "metadata": {},
   "source": [
    "#### Defining metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d40faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    actual_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (actual_positives + K.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision_value = precision(y_true, y_pred)\n",
    "    recall_value = recall(y_true, y_pred)\n",
    "    return 2 * ((precision_value * recall_value) / (precision_value + recall_value + K.epsilon()))\n",
    "\n",
    "def fnr(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "    return false_negatives / (true_positives + false_negatives + K.epsilon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of custom objects\n",
    "custom_objects = {\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1_score,\n",
    "    'fnr': fnr\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a8d6e",
   "metadata": {},
   "source": [
    "### Training one CNN per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68bc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(X_train, y_train, X_val, y_val, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 3, activation='relu', input_shape=(33, 1)))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy', precision, recall, f1_score, fnr])\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7965e60a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets = [first_augmented_dataset, second_augmented_dataset, third_augmented_dataset, fourth_augmented_dataset, fifth_augmented_dataset]\n",
    "\n",
    "models = []\n",
    "histories = []\n",
    "for dataset in datasets:\n",
    "    X = dataset.drop(columns=['class', 'objid', 'specobjid'])\n",
    "    y = dataset['class']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    y_val = label_encoder.transform(y_val)\n",
    "    y_test = label_encoder.transform(y_test)\n",
    "\n",
    "    y_train_one_hot = to_categorical(y_train, num_classes)\n",
    "    y_val_one_hot = to_categorical(y_val, num_classes)\n",
    "    y_test_one_hot = to_categorical(y_test, num_classes)\n",
    "\n",
    "    model, history = cnn_model(X_train, y_train_one_hot, X_val, y_val_one_hot, num_classes)\n",
    "\n",
    "    models.append(model)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd697d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # After training all models\n",
    "# best_model_performance = float('inf')\n",
    "# best_model_index = -1\n",
    "\n",
    "# for index in range(len(datasets)):\n",
    "#     # Load the saved model\n",
    "#     model = load_model(f'best_model_{index}.model', custom_objects=custom_objects)\n",
    "\n",
    "#     # Retrieve the corresponding validation set\n",
    "#     X_val, y_val_one_hot = validation_sets[index]\n",
    "\n",
    "#     # Evaluate the model using the corresponding validation set\n",
    "#     val_loss, val_accuracy, val_precision, val_recall, val_f1_score, val_fnr = model.evaluate(X_val, y_val_one_hot)\n",
    "\n",
    "#     # Compare performance to find the best model\n",
    "#     if val_loss < best_model_performance:\n",
    "#         best_model_performance = val_loss\n",
    "#         best_model_index = index\n",
    "\n",
    "# print(f\"Best model is model {best_model_index} with validation loss {best_model_performance}\")\n",
    "\n",
    "# # After finding the best model\n",
    "# X_test, y_test = test_sets[best_model_index]\n",
    "# best_scaler = scalers[best_model_index]  # Get the scaler used for the best model's dataset\n",
    "\n",
    "# # Scale X_test using the best model's scaler\n",
    "# X_test_scaled = best_scaler.transform(X_test)\n",
    "# if X_test_scaled.ndim == 2:\n",
    "#     X_test_scaled = np.expand_dims(X_test_scaled, axis=-1)\n",
    "\n",
    "# # One-hot encode y_test\n",
    "# y_test_one_hot = to_categorical(y_test, num_classes)\n",
    "\n",
    "# # Load the best model\n",
    "# best_model = load_model(f'best_model_{best_model_index}.model', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52fe770",
   "metadata": {},
   "source": [
    "### Visualizing the training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2bf31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'fnr']\n",
    "\n",
    "last_epoch_metrics = {metric: [] for metric in metrics}\n",
    "\n",
    "for history in histories:\n",
    "    for metric in metrics:\n",
    "        last_epoch_metric = history.history[metric][-1]\n",
    "        last_epoch_metrics[metric].append(last_epoch_metric)\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    for i in range(len(datasets)):\n",
    "        plt.plot([f'Dataset {i+1}'], [last_epoch_metrics[metric][i]], marker='o', label=f'Dataset {i+1}')\n",
    "    \n",
    "    plt.title(f'Comparison of {metric} for Different Datasets (Last Epoch)')\n",
    "    plt.xlabel('Dataset')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_fnr = model.evaluate(X_test, y_test)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "    print(f\"Test Precision: {test_precision}\")\n",
    "    print(f\"Test Recall: {test_recall}\")\n",
    "    print(f\"Test F1 Score: {test_f1_score}\")\n",
    "    print(f\"Test FNR: {test_fnr}\")\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Other analyses can be added here (like ROC curves, Precision-Recall curves, etc.)\n",
    "\n",
    "    return test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, cm\n",
    "\n",
    "# Assuming X_test and y_test_one_hot are your test datasets\n",
    "evaluate_model(model, X_test, y_test_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_metrics(test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, confusion_matrix):\n",
    "    # Plotting metrics\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'FNR']\n",
    "    values = [test_accuracy, test_precision, test_recall, test_f1_score, test_fnr]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Bar plot for metrics\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = sns.barplot(x=metrics, y=values)\n",
    "    plt.title('Test Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    \n",
    "    # Annotate values on top of bars\n",
    "    for bar in bars.patches:\n",
    "        bars.annotate(format(bar.get_height(), '.2f'), \n",
    "                      (bar.get_x() + bar.get_width() / 2, \n",
    "                       bar.get_height()), ha='center', va='center',\n",
    "                       size=10, xytext=(0, 8),\n",
    "                       textcoords='offset points')\n",
    "\n",
    "    # Adjusting ticks for readability\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    if confusion_matrix is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate the model and get metrics and confusion matrix\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, cm = evaluate_model(model, X_test, y_test_one_hot)\n",
    "\n",
    "# Example usage\n",
    "plot_test_metrics(test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytfenv",
   "language": "python",
   "name": "mytfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
