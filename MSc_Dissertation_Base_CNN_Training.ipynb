{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb86aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag = 0\n",
    "\n",
    "# if flag == 0:\n",
    "#   !pip install pandas numpy scikit-learn seaborn matplotlib scipy nltk tensorflow keras transformers\n",
    "#   flag = 1\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import concatenate, Concatenate\n",
    "from keras.layers import Input, Embedding, Conv1D, Conv2D, GlobalMaxPooling1D, GlobalAveragePooling1D, Flatten, MaxPooling1D, MaxPooling2D, Dense, Dropout, Reshape\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import transformers\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.optimizers.legacy import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6955fe4c",
   "metadata": {},
   "source": [
    "#### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68586b32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('SDSS_DR18.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641704d",
   "metadata": {},
   "source": [
    "#### Check column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c7896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7eb556",
   "metadata": {},
   "source": [
    "#### Check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "print(\"Number of duplicate rows:\", num_duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414287f6",
   "metadata": {},
   "source": [
    "#### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bfb5e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "column_names = df.columns.values.tolist()\n",
    "\n",
    "print(\"Column name \\t Count of missing values \\t Percentage of missing value to total rows\")\n",
    "for col in column_names:\n",
    "    count_nan = df[col].isnull().sum()\n",
    "    pct_nan = count_nan / len(df) * 100\n",
    "    if col in ['ra', 'dec', 'u', 'g', 'r', 'i', 'z']:\n",
    "        print(col + \" - \\t\\t\\t\" + str(count_nan) + \" \\t\\t\\t\\t\" + str(round(pct_nan, 2)) + \"%\")\n",
    "    else:\n",
    "        print(col + \" - \\t\\t\" + str(count_nan) + \" \\t\\t\\t\\t\" + str(round(pct_nan, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abab087",
   "metadata": {},
   "source": [
    "#### Data split for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['class', 'objid', 'specobjid'])\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e41103",
   "metadata": {},
   "source": [
    "#### Scaling all the numerical data to  standard scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554bb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed7c31",
   "metadata": {},
   "source": [
    "#### Dataset split into train, test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e0d3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b377341",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d5431e",
   "metadata": {},
   "source": [
    "#### Label encoding target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324fac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
    "galaxy_index = class_mapping['GALAXY']\n",
    "qso_index = class_mapping['QSO']\n",
    "star_index = class_mapping['STAR']\n",
    "print(\"Galaxy class index:\", galaxy_index)\n",
    "print(\"QSO class index:\", qso_index)\n",
    "print(\"Star class index:\", star_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970b524",
   "metadata": {},
   "source": [
    "#### One hot encoding target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = to_categorical(y_train, num_classes)\n",
    "y_val_one_hot = to_categorical(y_val, num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15815068",
   "metadata": {},
   "source": [
    "#### Checking number of instances for train, test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rows = X_train.shape[0]\n",
    "X_test_rows = X_test.shape[0]\n",
    "X_val_rows = X_val.shape[0]\n",
    "y_train_rows = y_train.shape[0]\n",
    "y_test_rows = y_test.shape[0]\n",
    "y_val_rows = y_val.shape[0]\n",
    "\n",
    "print(\"Input for train:\", X_train_rows)\n",
    "print(\"Input for test:\", X_test_rows)\n",
    "print(\"Input for validation:\", X_val_rows)\n",
    "print(\"Target for train:\", y_train_rows)\n",
    "print(\"Target for test:\", y_test_rows)\n",
    "print(\"Target for validation:\", y_val_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d46a0a",
   "metadata": {},
   "source": [
    "#### Checking shape of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b15493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    actual_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (actual_positives + K.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision_value = precision(y_true, y_pred)\n",
    "    recall_value = recall(y_true, y_pred)\n",
    "    return 2 * ((precision_value * recall_value) / (precision_value + recall_value + K.epsilon()))\n",
    "\n",
    "def fnr(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "    return false_negatives / (true_positives + false_negatives + K.epsilon())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c99d27",
   "metadata": {},
   "source": [
    "## Base CNN Xb training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da275841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(X_train, y_train, X_val, y_val, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 3, activation='relu', input_shape=(33, 1)))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Add dropout to prevent overfitting\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy', precision, recall, f1_score, fnr])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f89f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train_and_evaluate_model(X_train, y_train_one_hot, X_val, y_val_one_hot, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b549e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_fnr = model.evaluate(X_test, y_test)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "    print(f\"Test Precision: {test_precision}\")\n",
    "    print(f\"Test Recall: {test_recall}\")\n",
    "    print(f\"Test F1 Score: {test_f1_score}\")\n",
    "    print(f\"Test FNR: {test_fnr}\")\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    return test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, cm\n",
    "\n",
    "evaluate_model(model, X_test, y_test_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_metrics(test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, confusion_matrix):\n",
    "    # Plotting metrics\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'FNR']\n",
    "    values = [test_accuracy, test_precision, test_recall, test_f1_score, test_fnr]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Bar plot for metrics\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = sns.barplot(x=metrics, y=values)\n",
    "    plt.title('Test Metrics')\n",
    "    plt.ylabel('Value')\n",
    "    \n",
    "    # Annotate values on top of bars\n",
    "    for bar in bars.patches:\n",
    "        bars.annotate(format(bar.get_height(), '.2f'), \n",
    "                      (bar.get_x() + bar.get_width() / 2, \n",
    "                       bar.get_height()), ha='center', va='center',\n",
    "                       size=10, xytext=(0, 8),\n",
    "                       textcoords='offset points')\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    if confusion_matrix is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, cm = evaluate_model(model, X_test, y_test_one_hot)\n",
    "\n",
    "plot_test_metrics(test_accuracy, test_precision, test_recall, test_f1_score, test_fnr, cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytfenv",
   "language": "python",
   "name": "mytfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
